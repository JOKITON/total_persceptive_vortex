{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/Shared/42/ML/projects/total_perspective_vortex/sample_data/MEG/sample/sample_audvis_raw.fif...\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Reading 0 ... 166799  =      0.000 ...   277.714 secs...\n",
      "320 events found on stim channel STI 014\n",
      "Event IDs: [ 1  2  3  4  5 32]\n",
      "Opening raw data file /Users/Shared/42/ML/projects/total_perspective_vortex/sample_data/MEG/sample/ernoise_raw.fif...\n",
      "Isotrak not found\n",
      "    Read a total of 3 projection items:\n",
      "        PCA-v1 (1 x 102)  idle\n",
      "        PCA-v2 (1 x 102)  idle\n",
      "        PCA-v3 (1 x 102)  idle\n",
      "    Range : 19800 ... 85867 =     32.966 ...   142.965 secs\n",
      "Ready.\n",
      "Reading 0 ... 66067  =      0.000 ...   109.999 secs...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No matching events found for Task 4 (imagine opening and closing both fists or both feet) (event id 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 67\u001b[0m\n\u001b[1;32m     62\u001b[0m \teeg_data\u001b[38;5;241m.\u001b[39mplot_evoked_events(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask 3 (open and close both fists or both feet)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask 4 (imagine opening and closing both fists or both feet)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     64\u001b[0m \teeg_data\u001b[38;5;241m.\u001b[39mplot_evoked_events(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask 3 (open and close both fists or both feet)\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTask 4 (imagine opening and closing both fists or both feet)\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeg\u001b[39m\u001b[38;5;124m\"\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 67\u001b[0m \u001b[43mplot_clean_eeg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevent_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ml_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m75\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[1], line 41\u001b[0m, in \u001b[0;36mplot_clean_eeg\u001b[0;34m(config, event_dict, l_freq, h_freq)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\" eeg_data.compute_psd()\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124;03meeg_data.plot_psd() \"\"\"\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# Based on the plot, choose the number of components that explain 95% of the variance\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m pca \u001b[38;5;241m=\u001b[39m \u001b[43meeg_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_pca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m explained_variance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcumsum(pca\u001b[38;5;241m.\u001b[39mexplained_variance_ratio_)\n\u001b[1;32m     43\u001b[0m n_components \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(explained_variance \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.99\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m/Users/Shared/42/ML/projects/total_perspective_vortex/ica/eeg_model.py:56\u001b[0m, in \u001b[0;36mEEGData.apply_pca\u001b[0;34m(self, n_components)\u001b[0m\n\u001b[1;32m     52\u001b[0m tmin, tmax \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;241m0.3\u001b[39m\n\u001b[1;32m     53\u001b[0m picks \u001b[38;5;241m=\u001b[39m mne\u001b[38;5;241m.\u001b[39mpick_types(\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw_eeg_filtered\u001b[38;5;241m.\u001b[39minfo, meg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eeg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, stim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eog\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbads\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     55\u001b[0m )\n\u001b[0;32m---> 56\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEpochs\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_eeg_filtered\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     68\u001b[0m pca \u001b[38;5;241m=\u001b[39m UnsupervisedSpatialFilter(PCA(\u001b[38;5;241m30\u001b[39m), average\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     69\u001b[0m pca_data \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mfit_transform(epochs)\n",
      "File \u001b[0;32m<decorator-gen-228>:10\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, raw, events, event_id, tmin, tmax, baseline, picks, preload, reject, flat, proj, decim, reject_tmin, reject_tmax, detrend, on_missing, reject_by_annotation, metadata, event_repeated, verbose)\u001b[0m\n",
      "File \u001b[0;32m/Users/Shared/42/ML/.venv/lib/python3.12/site-packages/mne/epochs.py:3580\u001b[0m, in \u001b[0;36mEpochs.__init__\u001b[0;34m(self, raw, events, event_id, tmin, tmax, baseline, picks, preload, reject, flat, proj, decim, reject_tmin, reject_tmax, detrend, on_missing, reject_by_annotation, metadata, event_repeated, verbose)\u001b[0m\n\u001b[1;32m   3575\u001b[0m     events, event_id, annotations \u001b[38;5;241m=\u001b[39m _events_from_annotations(\n\u001b[1;32m   3576\u001b[0m         raw, events, event_id, annotations, on_missing\n\u001b[1;32m   3577\u001b[0m     )\n\u001b[1;32m   3579\u001b[0m \u001b[38;5;66;03m# call BaseEpochs constructor\u001b[39;00m\n\u001b[0;32m-> 3580\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3581\u001b[0m \u001b[43m    \u001b[49m\u001b[43minfo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3582\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3584\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3585\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3586\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3587\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3588\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbaseline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3589\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3590\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpicks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpicks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3591\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreject\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3592\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mflat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3593\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3594\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreject_tmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreject_tmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3595\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreject_tmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreject_tmax\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetrend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdetrend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_missing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_missing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_at_end\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevent_repeated\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevent_repeated\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mraw_sfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mraw_sfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mannotations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mannotations\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3604\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<decorator-gen-212>:10\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, info, data, events, event_id, tmin, tmax, baseline, raw, picks, reject, flat, decim, reject_tmin, reject_tmax, detrend, proj, on_missing, preload_at_end, selection, drop_log, filename, metadata, event_repeated, raw_sfreq, annotations, verbose)\u001b[0m\n",
      "File \u001b[0;32m/Users/Shared/42/ML/.venv/lib/python3.12/site-packages/mne/epochs.py:491\u001b[0m, in \u001b[0;36mBaseEpochs.__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m val \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m events[:, \u001b[38;5;241m2\u001b[39m]:\n\u001b[1;32m    490\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo matching events found for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (event id \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 491\u001b[0m         \u001b[43m_on_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mon_missing\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;66;03m# ensure metadata matches original events size\u001b[39;00m\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselection \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(events))\n",
      "File \u001b[0;32m/Users/Shared/42/ML/.venv/lib/python3.12/site-packages/mne/utils/check.py:1218\u001b[0m, in \u001b[0;36m_on_missing\u001b[0;34m(on_missing, msg, name, error_klass)\u001b[0m\n\u001b[1;32m   1216\u001b[0m on_missing \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarning\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m on_missing\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1218\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_klass(msg)\n\u001b[1;32m   1219\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m on_missing \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1220\u001b[0m     warn(msg)\n",
      "\u001b[0;31mValueError\u001b[0m: No matching events found for Task 4 (imagine opening and closing both fists or both feet) (event id 6)"
     ]
    }
   ],
   "source": [
    "\"\"\" Plots the alpha band (8-12 Hz) power spectral density (PSD) of EEG/MEG data and empty room noise. \"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mne\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from eeg_model import EEGData\n",
    "\n",
    "script_path = Path().resolve()\n",
    "folder = (script_path / \"../\").resolve()\n",
    "\n",
    "JSON_PATH = script_path / \"config.json\"\n",
    "EVENTS_PATH = script_path / \"events.json\"\n",
    "\n",
    "with open(JSON_PATH, \"r\") as f:\n",
    "    config = json.load(f)\n",
    "\n",
    "with open(EVENTS_PATH, \"r\") as f:\n",
    "    event_dict = json.load(f)\n",
    "\n",
    "def\tplot_clean_eeg(config, event_dict, l_freq, h_freq):\n",
    "\n",
    "\t# Get the sample data,\n",
    "\tsample_data_raw_file = folder / config[\"eeg_path\"]\n",
    "\tsample_data_raw_noise = folder / config[\"noise_path\"]\n",
    "\n",
    "\teeg_data = EEGData(sample_data_raw_file, sample_data_raw_noise, l_freq=l_freq, h_freq=h_freq, verbose=True)\t\n",
    "\teeg_data.load_event_dict(event_dict)\n",
    "\n",
    "\traw_data = eeg_data.get_raw_data()\n",
    "\tevents, event_dict = eeg_data.get_events()\n",
    "\n",
    "\teeg_data.filter_data(tmax=None, verbose=False)\n",
    "\n",
    "\t# Plot difference between EEG & Room Noise\n",
    "\t\"\"\" eeg_data.compute_psd()\n",
    "\teeg_data.plot_psd() \"\"\"\n",
    "\n",
    "\t# Based on the plot, choose the number of components that explain 95% of the variance\n",
    "\tpca = eeg_data.apply_pca()\n",
    "\texplained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\tn_components = np.argmax(explained_variance >= 0.99) + 1\n",
    "\n",
    "\tprint(f\"Number of components to explain 95% variance: {n_components}\")\n",
    "\n",
    "\t# Apply PCA with the chosen number of components\n",
    "\teeg_data.apply_pca(n_components=n_components)\n",
    "\n",
    "\t# Compute ICA\n",
    "\tclean_data = eeg_data.compute_ica(n_components, plot_comp=False,\n",
    "    \tplot_arts=False, verbose=False)\n",
    "\t# Plot cleaned EEG after ICA\n",
    "\teeg_data.plot_clean_eeg()\n",
    "\n",
    "\t# Plot evoked events on EEG & MEG Data\n",
    "\teeg_data.plot_evoked_events(\"Task 1 (open and close left or right fist)\",\n",
    "        \"Task 2 (imagine opening and closing left or right fist)\", type=\"eeg\", verbose=False)\n",
    "\teeg_data.plot_evoked_events(\"Task 1 (open and close left or right fist)\",\n",
    "        \"Task 2 (imagine opening and closing left or right fist)\", type=\"meg\", verbose=False)\n",
    "\n",
    "\teeg_data.plot_evoked_events(\"Task 3 (open and close both fists or both feet)\",\n",
    "        \"Task 4 (imagine opening and closing both fists or both feet)\", type=\"eeg\", verbose=False)\n",
    "\teeg_data.plot_evoked_events(\"Task 3 (open and close both fists or both feet)\",\n",
    "        \"Task 4 (imagine opening and closing both fists or both feet)\", type=\"meg\", verbose=False)\n",
    "\n",
    "plot_clean_eeg(config, event_dict, l_freq=0, h_freq=75)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
